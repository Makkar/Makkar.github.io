[{"authors":["admin"],"categories":null,"content":"I am a graduate student at Columbia University interested in probabilistic machine learning. I am affiliated with the Electrical Engineering Department and the Data Science Institute and am part of a thriving machine learning community here at Columbia. I am advised by Prof. John Paisley.\nPreviously, I was at Goldman Sachs working with Dr. Howard Karloff on machine learning applications for surveillance models. I received my Bachelors degree from Indian Institute of Technology (IIT) Delhi.\nIf you\u0026rsquo;d like to chat, feel free to write me at a \u0026lsquo;dot\u0026rsquo; makkar \u0026lsquo;at\u0026rsquo; columbia \u0026lsquo;dot\u0026rsquo; edu.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://makkar.github.io/author/aditya-makkar/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/aditya-makkar/","section":"authors","summary":"I am a graduate student at Columbia University interested in probabilistic machine learning. I am affiliated with the Electrical Engineering Department and the Data Science Institute and am part of a thriving machine learning community here at Columbia.","tags":null,"title":"Aditya Makkar","type":"authors"},{"authors":[],"categories":[],"content":"$$ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\RR}{\\overline{\\mathbb{R}}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\F}{\\mathbb{F}} \\newcommand{\\FF}{\\mathcal{F}} \\newcommand{\\Q}{\\mathbb{Q}} \\newcommand{\\N}{\\mathbb{N}} \\newcommand{\\Z}{\\mathbb{Z}} \\newcommand{\\X}{\\mathcal{X}} \\newcommand{\\H}{\\mathcal{H}} \\newcommand{\\e}{\\epsilon} \\newcommand{\\limn}{\\lim_{n \\to \\infty}} \\newcommand\\inner[2]{\\langle #1, #2 \\rangle} \\newcommand{\\norm}[1]{\\lVert#1\\rVert} \\newcommand{\\conj}[1]{\\overline{#1}} \\DeclareMathOperator{\\dx}{dx} \\DeclareMathOperator{\\dmu}{d\\mu} $$\nIntroduction The word \u0026ldquo;kernel\u0026rdquo; is heavily overloaded, but for our purposes it is, intuitively, a similarity measure that can be thought of as an inner product in some feature space.\nWe usually have the following framework: The input space $\\X$ which contains our observations/inputs/features is either not rich enough (for example, if there is no linear boundary separating the two classes in a binary classification problem) or not convenient (for example, if our inputs are strings), and therefore we want to work is some other space we call feature space $\\H$. Suppose we have a map which takes our inputs from $\\X$ to $\\H$: $$ \\Phi : \\X \\to \\H $$ Then the class of kernels we are interested in are those for which is it possible to write $$ k(x,y) = \\langle \\Phi(x), \\Phi(y) \\rangle, \\quad x,y \\in \\X $$ What kind of functions, $k : \\H \\times \\H \\to \\R$ admit such a representation? We aim to be able to answer this question and many others in this series of articles on kernel theory.\nIn this article, I aim to introduce the necessary concepts from analysis, linear algebra, and functional analysis so as to understand Reproducing Kernel Hilbert Spaces (RKHS) and a few of their basic properties. This beautiful theory will require some patience from the reader.\nBackground A topic like this requires quite a bit of background before we can get to the interesting results like the one above. It\u0026rsquo;s always easy to get lazy and assume all the necessary background from the reader and get straight to the meat, but I want to write an article which I would have found useful had I had it when I started learning about kernel theory. With that being said, I am under no illusion that a much better way to learn this background would be to read a functional analysis text if you have the time.\nLinear spaces Definition 1: A linear space, or alternatively a vector space, over a field $\\F$ ($\\F$ is $\\R$ or $\\C$ for our purposes) is a set $V$ of elements called vectors (the elements of $\\F$ are called scalars) satisfying:\n(A) To every pair, $x$ and $y$, of vectors in $V$ there corresponds a vector $x+y$, called the sum of $x$ and $y$, in such a way that\n addition is commutative, $x+y = y+x$, addition is associative, $x+(y+z) = (x+y)+z$, there exists in $V$ a unique vector $0$ such that $x+0=x$ for every vector $x$, and to every vector $x \\in V$ there corresponds a unique vector $-x$ such that $x+(-x)=0$.  (B) To every pair, $\\alpha \\in \\F$ and $x \\in V$, there corresponds a vector $\\alpha x \\in V$, called the product of $\\alpha$ and $x$, in such a way that\n multiplication by scalars is associative, $\\alpha(\\beta x) = (\\alpha \\beta)x$, and $1x = x$ for every vector $x$.  (C) Finally the distributive properties\n $\\alpha(x+y) = \\alpha x + \\alpha y$, and $(\\alpha + \\beta) x = \\alpha x + \\beta x$.  Examples  The Euclidean spaces $\\R^n$ are vector spaces over the real field. $\\C^n$ are vector spaces over $\\C$. The set of all polynomials, with complex coefficients, in a variable $t$ is a vector space over $\\C$. The set $C$ of all continuous complex functions on the unit interval $[0,1]$ is a vector space over $\\C$.  Definition 2: A linear transformation of a linear space $V$ into a linear space $W$ is a mapping $T: V \\to W$ such that $$ T(\\alpha x + \\beta y) = \\alpha T(x) + \\beta T(y), \\quad (x,y \\in V;\\; \\alpha, \\beta \\in \\F) $$\nDefinition 3: In the special case in which $W$ above is a field, $T$ is called a linear functional.\nNote that we often write $Tx$ instead of $T(x)$, if $T$ is linear.\nDefinition 4: Let $\\mu$ be a positive measure on an arbitrary measurable space $X$. We define $L^1(\\mu)$ to be the collection of all complex measurable functions $f$ on $X$ for which $$ \\int_X |f| \\dmu \u0026lt; \\infty $$\nIt can be shown that for every $f, g \\in L^1(\\mu)$ and for every $\\alpha, \\beta \\in \\C$, we have $\\alpha f + \\beta g \\in L^1(\\mu)$, and $$ \\int_X (\\alpha f + \\beta g) \\dmu = \\alpha \\int_X f \\dmu + \\beta \\int_X g \\dmu $$\nThus, $L^1(\\mu)$ is a vector space, and the mapping $F: L^1(\\mu) \\to \\R$ defined by $$ F(f) = \\int_X |f| \\dmu, \\quad f \\in L^1(\\mu) $$ is a linear functional.\nInner products and norms Definition 5: If $V$ be a linear space over $\\C$, an inner product on $V$ is a function $\\langle \\cdot , \\cdot \\rangle: V \\times V \\to \\C$ such that for all $\\alpha, \\beta \\in \\C$, and all $x,y,z \\in V$, the following are satisfied:\n Linearity in the first argument: $\\langle \\alpha x + \\beta y, z \\rangle = \\alpha \\langle x,z \\rangle + \\beta \\langle y,z \\rangle$, Conjugate symmetry: $\\inner{x}{y} = \\conj{\\inner{y}{x}}$, Positivity: $\\inner{x}{x} \\geq 0$, If $\\inner{x}{x} = 0$, then $x=0$.  A function satisfying only the first three properties is called a semi-inner product on $V$.\nAn immediate consequences of this definition: For every $y \\in V$, the mapping $F: V \\to \\C$ defined by $$ F(x) = \\inner{x}{y}, \\quad (x \\in V) $$ is a linear functional on $V$.\nDefinition 6: If $V$ be a linear space over $\\C$, a norm on $V$ is a non-negative function $\\norm{\\cdot} : V \\to \\R$ such that for all $\\alpha \\in \\C$, and all $x,y \\in V$, the following are satisfied:\n Subadditivity: $\\norm{x+y} \\leq \\norm{x} + \\norm{y}$, Absolutely homogenous: $\\norm{\\alpha x} = |\\alpha| \\norm{x}$, Positive definite: $\\norm{x} = 0 \\implies x = 0$.  Given an inner product, we can define a norm as follows: $$ \\norm{x} = \\sqrt{\\inner{x}{x}} $$\nA classic result useful in many proofs:\nTheorem 1: Schwarz inequality $$|\\inner{x}{y}| \\leq \\norm{x} \\, \\lVert y \\rVert$$ Equality hold for $y = \\alpha x$ or $y=0$.\nThe proof is not too difficult.\nDefinition 7: The virtue of norm on a vector space $V$ is that $$ d(x,y) := \\norm{ x-y } $$ defines a metric on $V$ so that $V$ becomes a metric space.\nDefinition 8: If $0 \u0026lt; p \u0026lt; \\infty$ and if $f$ is a complex measurable function on $X$, define $$ \\norm{f}_p := \\left( \\int_X |f|^p \\dmu \\right)^{1/p} $$ and let $L^p(\\mu)$ consist of all $f$ for which $\\norm{f}_p \u0026lt; \\infty$. We call $\\norm{f}_p$ the $L^p$-norm of $f$.\nHilbert spaces Definition 9: An inner product space, or alternatively a pre-Hilbert space, is a linear space with an inner product defined on it.\nDefinition 10: A pre-Hilbert space $\\H$ is called a Hilbert space if it is complete in the metric $d$ (see Definition 7).\nNote that a metric space $M$ is called complete if every Cauchy sequence of points in $M$ has a limit that is also in $M$ or, alternatively, if every Cauchy sequence in $M$ converges in $M$.\nExamples  The set $\\C^n$ is a Hilbert space. The set $C$ of all continuous complex functions on the unit interval $[0,1]$ defined above is an inner product space if we define $$ \\inner{f}{g} := \\int_0^1 f(x) \\conj{g(x)} \\dx $$ but is not a Hilbert space. $L^2(\\mu)$ is a Hilbert space, with inner product $$ \\inner{f}{g} := \\int_X f \\, \\conj{g} \\dmu $$  Definition 11: Consider a linear space $\\FF$ of functions each of which is a mapping from a set $X$ into $\\F$. For $x \\in X$, a linear evaluation functional is a linear functional $E_x$ that is defined as $$ E_x(f) = f(x), \\quad (f \\in \\FF) $$ In other words, a linear evaluation function with respect to $x \\in X$ evaluates each function at $x$.\nIn general, the evaluation functional is not continuous. This means we can have $f_n \\to f$ but $E_x(f_n)$ does not converge to $E_x(f)$. Intuitively, this is because Hilbert spaces can contain very unsmooth functions. We will later consider a special type of Hilbert space, Reproducing Kernel Hilbert Space where evaluation functional is continuous.\nA lemma that will be useful later on:\nLemma 1: Let $\\H$ be a Hilbert space and $L:\\H \\to \\F$ a linear functional. The following statements are equivalent:\n $L$ is continuous. $L$ is continuous at $0$. $L$ is continuous at some point. $L$ is bounded, i.e., there is a constant $c \u0026gt; 0$ such that $|L(f)| \\leq c \\norm{f}$ for every $f \\in \\H$.  Proof: It is clear that $(1) \\implies (2) \\implies (3)$, and $(4) \\implies (2)$. Let\u0026rsquo;s show that $(3) \\implies (1)$, and $(2) \\implies (4)$.\n$(3) \\implies (1)$: Suppose $L$ is continuous at $f$ and $g$ is any point in $\\H$. If $g_n \\to g$ in $\\H$, then $g_n - g + f \\to f$. By assumption $L(f) = \\limn L(g_n - g + f) = \\limn L(g_n) - L(g) + L(f)$. Hence $L(g) = \\limn L(g_n)$.\n$(2) \\implies (4)$: The definition of continuity at $0$ implies that $L^{-1}(\\{\\alpha \\in \\F : |\\alpha| \u0026lt; 1\\})$ contains an open ball centered at $0$. Let $\\delta \u0026gt; 0$ be the radius of that open ball centered at $0$. Then for $f \\in \\H$ and $\\norm{f} \u0026lt; \\delta$ we have $|L(f)| \u0026lt; 1$. If $f$ is an arbitrary element of $\\H$ and $\\e \u0026gt; 0$, then $$ \\left\\lVert \\frac{\\delta f}{\\norm{f} + \\e} \\right\\rVert \u0026lt; \\delta $$ Hence, $$ 1 \u0026gt; \\left\\lvert L\\left( \\frac{\\delta f}{\\norm{f} + \\e} \\right) \\right\\rvert = \\frac{\\delta }{\\norm{f} + \\e} |L(f)| $$ Letting $\\e \\to 0$ we see that $(4)$ holds with $c = 1/\\delta$. $\\square$\nRiesz representation theorem We now come to a very important theorem called the Riesz representation theorem. The name Riesz has many theorems attached to it, but the one relevant to us is the following:\nTheorem 2: For each continuous linear functional $\\phi$ on a Hilbert space $\\H$, there exists a unique $g \\in \\H$ such that $$\\phi(f) = \\inner{f}{g}\\, , \\quad (f \\in \\H) $$\nI\u0026rsquo;ll skip the proof as it\u0026rsquo;s not easy and will unnecessarily make this article abstruse.\nSide-note: In the mathematical treatment of quantum mechanics, this theorem can be seen as a justification for the popular bra–ket notation.\nReproducing Kernel Hilbert Spaces (RKHS) Definition 12: Let $X$ be a set. We will call a set $\\H$ of functions from $X$ to $\\F$ a Reproducing Kernel Hilbert Space (RKHS) on $X$ if\n $\\H$ is a vector space, $\\H$ is endowed with an inner product, $\\inner{\\cdot}{\\cdot}$, with respect to which $\\H$ is a Hilbert space, for every $x \\in X$, the linear evaluation functional $E_x : \\H \\to \\F$, is bounded (or continuous, as seen from Lemma-1).  If $\\H$ is an RKHS on $X$, then an application of the Riesz representation theorem shows that the linear evaluation functional is given by the inner product with a unique vector in $\\H$. Therefore, for each $x \\in X$, there exists a unique vector $k_x \\in \\H$, such that for every $f \\in \\H$, $$ f(x) = E_x(f) = \\inner{f}{k_x} $$\nDefinition 13: The function $k_x$ is called the reproducing kernel for the point $x$. The function $K: X \\times X \\to \\F$ defined by $$ K(x,y) = k_y(x) $$ is called the reproducing kernel for $\\H$.\nNote that we have $$ K(x,y) = k_y(x) = \\inner{k_y}{k_x} = \\conj{\\inner{k_x}{k_y}} = \\conj{K(y,x)}$$\nAlso, $$ \\norm{E_y}^2 = \\norm{k_y}^2 = \\inner{k_y}{k_y} = K(y,y) $$\nExample The first question that comes to mind is if any Reproducing Kernel Hilbert Spaces exist. The following example answers this question in the affirmative.\nWe saw before that $\\C^n$ is a Hilbert space. We can show that $\\C^n$ is in fact an RKHS. Let $X = \\{1, 2, \\ldots, n\\}$, then we can view $v \\in \\C$ as a function $V : X \\to \\C$, where $V(j) = v_j$. The linear evaluation functionals are of course bounded for every $x \\in X$ and we have $$ V(j) = v_j = \\inner{V}{e_j}\\,, \\quad (j \\in X) $$ where $e_j$ is a vector with $1$ at $j$th position and $0$ everywhere else. Therefore, the reproducing kernel for the point $x \\in X$ is $e_x$ and the reproducing kernel can be thought as the identity matrix.\nCan there be multiple reproducing kernels for an RKHS? The following theorem answers this question.\nTheorem 3: If an RKHS $\\H$ of functions on a set $X$ admits a reproducing kernel, $K$, then $K$ is uniquely determined by $\\H$.\nProof: Suppose that there exists another reproducing kernel $K'$ for $\\H$. Then $$ \\norm{k_y - k\u0026rsquo;_y} = \\inner{k_y - k\u0026rsquo;_y}{k_y - k\u0026rsquo;_y} = \\inner{k_y - k\u0026rsquo;_y}{k_y} - \\inner{k_y - k\u0026rsquo;_y}{k\u0026rsquo;_y} = (k_y - k\u0026rsquo;_y)(y) - (k_y - k\u0026rsquo;_y)(y) = 0 $$ for any $y \\in X$. In other words, $k_y(x) = k\u0026rsquo;_y(x)$ for every $x \\in X$ by the positive definite property of norms and hence the kernel is unique. $\\square$\nEpilogue We covered quite a lot of ground in this blog post but I didn\u0026rsquo;t even define a kernel as we commonly use in machine learning! In the next post I will do that and cover its fundamental properties.\n","date":1593826510,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593826510,"objectID":"0947cda7e02dd4e13d4c0959ccd45212","permalink":"https://makkar.github.io/post/kernels/","publishdate":"2020-07-03T21:35:10-04:00","relpermalink":"/post/kernels/","section":"post","summary":"Functional analysis background for kernel theory.","tags":[],"title":"Kernels - Part 0","type":"post"},{"authors":[],"categories":[],"content":"I want to show how these two concepts are a single mathematical idea.\nPartition A partition of a non-empty set, $X$, is a disjoint class $\\{X_i\\}_{i \\in I}$ of non-empty subsets of $X$ whose union is $X$. The $X_i$'s are called the partition sets.\nFor example, if $X = \\mathbb{R}$, then $X$ can be partitioned as $$ X = \\bigcup_{n \\in \\mathbb{Z}}[n, n+1) $$\nBinary Relation A binary relation, or simply relation, $R$, in the set $X$ is a subset of $X \\times X$.\nFor $x, y \\in X$, we denote the fact $(x,y) \\in R$ by writing $x R y$. A function may be defined as a special kind of binary relation.\nEquivalence relation Let\u0026rsquo;s assume that a partition of our non-empty set $X$ is given, and we associate with this partition a relation, $\\sim$, in $X$ defined as follows: $x \\sim y$ if $x$ and $y$ belong to the same partition set. It can easily checked that the relation $\\sim$ satisfies:\n $x \\sim x$ for every $x \\in X$ (reflexivity); $x \\sim y \\implies y \\sim x$ (symmetry); $x \\sim y$ and $y \\sim z$ $\\implies$ $x \\sim z$ (transitivity).  Any relation in $X$ which possesses these three properties is called an equivalence relation in $X$.\nExamples  Let $X = \\mathbb{Z}$ and let $x \\sim y$ if $2 | x-y$ for $x,y \\in X$. Then clearly $\\sim$ is an equivalence relation in $X$. Let $X$, $Y$ be any non-empty sets and $f$ be a mapping from $X$ onto $Y$. Let $x \\sim y$ if $f(x) = f(y)$ for $x,y \\in A$. This defines an equivalence relation in $X$. Indeed, $f(x) = f(x)$, and so $x \\sim x$. If $f(x) = f(y)$ then $f(y) = f(x)$, and so $x \\sim y \\implies y \\sim x$. Finally, if $f(x) = f(y)$ and $f(y) = f(z)$ then $f(x) = f(z)$, and so $x \\sim y$ and $y \\sim z$ $\\implies$ $x \\sim z$. The first example is a special case of this one if we take $X = \\mathbb{Z}$, $Y = \\{0,1\\}$ and $f(x) = x \\mod 2$.  \u0026ldquo;Relation\u0026rdquo; to partition We have just seen that each partition of $X$ has associated with it a natural equivalence relation in $X$. Let us now reverse the situation and show that a given equivalence relation in $X$ determines a natural partition of $X$.\nLet $\\sim$ be an equivalence relation in $X$. For every $x \\in X$ define the set $$ [x] := \\{ y \\in X : y \\sim x\\} $$ called the equivalence set of $x$. We show that the class of all distinct equivalence sets forms a partition of $X$.\nBy reflexivity, $x \\in [x]$ for every $x \\in X$, and thus each equivalence set is non-empty and their union is $X$. We now need to show that any two equivalence sets $[x_1]$ and $[x_2]$ are either disjoint or identical. We prove this by showing that if $[x_1]$ and $[x_2]$ are not disjoint then they are identical. To this end, let $z$ be a common element of $[x_1]$ and $[x_2]$. Let $y$ be any element of $[x_1]$. Using transitivity, $$ y \\sim x_1 \\sim z \\sim x_2 $$ Therefore, $y \\in [x_2]$. Since $y$ was an arbitrary element of $[x_1]$, we get $[x_1] \\subseteq [x_2]$. We can similarly show that $[x_2] \\subseteq [x_1]$. In short, $[x_1] = [x_2]$.\nWe have shown that there is no real distinction between partitions of a set and equivalence relations in the set. They are two \u0026ldquo;equivalent\u0026rdquo; approaches for the same mathematical idea. The approach we choose in an application depends entirely on our own convenience.\n","date":1592695005,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592695005,"objectID":"d1bbc0efd74ed683d7616f54612bc205","permalink":"https://makkar.github.io/post/equivalence-relations/","publishdate":"2020-06-20T19:16:45-04:00","relpermalink":"/post/equivalence-relations/","section":"post","summary":"I want to show how these two concepts are a single mathematical idea.","tags":[],"title":"Partitions and Equivalence Relations","type":"post"},{"authors":[],"categories":[],"content":"","date":1592597042,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592597042,"objectID":"f666c79c96acdb6b8a4da2a4c84b4d24","permalink":"https://makkar.github.io/blog/blah-bloh/","publishdate":"2020-06-19T16:04:02-04:00","relpermalink":"/blog/blah-bloh/","section":"blog","summary":"","tags":[],"title":"Blah Bloh","type":"blog"},{"authors":[],"categories":[],"content":"$$ \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\RR}{\\overline{\\mathbb{R}}} \\newcommand{\\Q}{\\mathbb{Q}} \\newcommand{\\N}{\\mathbb{N}} \\newcommand{\\Z}{\\mathbb{Z}} \\newcommand{\\e}{\\epsilon} \\newcommand{\\limm}{\\lim_{n \\to \\infty}} \\newcommand{\\lims}{\\limsup_{n \\to \\infty}} \\newcommand{\\limi}{\\liminf_{n \\to \\infty}} \\newcommand{\\sn}{\\{s_n\\}} \\newcommand{\\snk}{\\{s_{n_k}\\}} \\newcommand{\\supk}{\\sup_{k \\geq n}} \\newcommand{\\infk}{\\inf_{k \\geq n}} \\newcommand{\\sups}{\\sup_{k \\geq n} s_k} \\newcommand{\\infs}{\\inf_{k \\geq n} s_k} \\newcommand{\\cc}{\\mathsf{c}} $$\nMost of what follows is taken from Rudin\u0026rsquo;s Principles of Mathematical Analysis.\nIntroduction The concept of upper and lower limits (commonly denoted by $\\limsup$ and $\\liminf$ respectively) shows up routinely when discussing the limiting behaviour of a sequence. For example, consider the Big O notation, $\\mathcal{O}$, defined as $f(n) = \\mathcal{O}(g(n))$ iff there exists a positive real number $c$ and an integer $N$ such that for every $n \\in \\Z$, $n \u0026gt; N$, we have $|f(n)| \\leq c g(n)$. This can be succinctly written as $$ \\lims \\frac{|f(n)|}{g(n)} \u0026lt; \\infty $$\nIn this post, I aim to expound on the concept of upper and lower limits so that the second formulation of Big O notation above becomes easier to understand than the first one.\nDefinitions I start with some definitions.\nDefinition 1: A sequence is function defined on the set $\\N$ of positive integers. If $f(n) = x_n$, for $n \\in \\N$, we denote the sequence $f$ by the symbol $\\{x_n\\}$, or sometimes by $x_1, x_2, \\ldots$.\nDefinition 2: A sequence $\\{p_n\\}$ in a metric space $X$ is said to converge if there is a point $p \\in X$ with the following property: For every $\\e \u0026gt; 0$ there is an integer $N$ such that $n \\geq N$ implies that $d(p_n, p) \u0026lt; \\e$. We write this as $\\limm p_n = p$ or as $p_n \\to p$.\nDefinition 3: Let $\\{s_n\\}$ be a sequence of real numbers with the following property: For every real $M$ there is an integer $N$ such that $n \\geq N$ implies $s_n \\geq M$. We then write $s_n \\to +\\infty$. Similarly for $s_n \\to -\\infty$.\nNote: The symbol $\\to$ is now used for certain type of divergent sequences as well.\nDefinition 4: Given a sequence $\\{p_n\\}$, consider a sequence $\\{n_k\\}$ of positive integers, such that $n_1 \u0026lt; n_2 \u0026lt; \\cdots$. Then the sequence $\\{p_{n_k}\\}$, which is a composition of the functions $\\{n_k\\}$ and $\\{p_n\\}$, is called a subsequence of ${p_n}$. If $\\{p_{n_k}\\}$ converges, its limit is called a subsequential limit of $\\{p_n\\}$.\nDefinition 5: Let $\\sn$ be a sequence of real numbers. Let $E$ be the set of numbers $x$ (in the extended real number system, i.e., $x \\in \\RR := \\R \\cup \\{+\\infty, -\\infty\\}$) such that $s_{n_k} \\to x$ for some subsequence $\\{s_{n_k}\\}$. Therefore, this set contains all the subsequential limits of $\\sn$ plus possibly the numbers $+\\infty$ and $-\\infty$. We define $$ s^* = \\sup E $$ $$ s_* = \\inf E $$ The numbers $s^*$ and $s_*$ are called the upper and lower limits of $\\sn$. We use the notation $$ \\lims s_n = s^* $$ $$ \\limi s_n = s_* $$ It immediately follows that $s_* \\leq s^*$.\nThe fact that $E$ is non-empty (and thus taking $\\sup$ or $\\inf$ makes sense) follows from the observation that either $\\sn$ is bounded or unbounded. If it is bounded then it must contain a convergent subsequence (Bolzano–Weierstrass theorem) and thus at least one element, or if it is unbounded then it must contain either $+\\infty$ or $-\\infty$.\nSome useful lemmas Now let us prove some interesting lemmas that will be useful later.\nLemma 1: The subsequential limits of a sequence $\\{p_n\\}$ in a metric space $X$ form a closed subset of $X$.\nProof: Let $E$ be the set of all subsequential limits of $\\{p_n\\}$ and let $q$ be a limit point of $E$. We have to show that $q \\in E$. To show this we will construct a subsequence of $\\{p_n\\}$ which converges to $q$.\nChoose $n_1$ so that $p_{n_1} \\neq q$. If no such $n_1$ exists, then $E$ has only one element, $q = p_1 = p_2 = \\cdots$, and there is nothing to prove. Define $\\delta = d(q, p_{n_1})$. Suppose $n_1, \\ldots, n_{i-1}$ are chosen. Since $q$ is a limit point of $E$, there is an $x \\in E$ with $d(q, x) \u0026lt; \\frac{\\delta}{2^i}$. Since $x \\in E$, there is an $n_i \u0026gt; n_{i-1}$ such that $d(x, p_{n_i}) \u0026lt; \\frac{\\delta}{2^i}$. Thus $$ d(q, p_{n_i}) \\leq d(q, x) + d(x, p_{n_i}) \u0026lt; \\frac{\\delta}{2^{i-1}} \\quad \\text{for } i = 1,2,\\ldots $$ This implies $p_{n_k} \\to q$, and thus $q \\in E$. $\\square$\nLemma 2: Let $F$ be a nonempty closed set of real numbers which is bounded above. Let $\\alpha = \\sup F$. Then $\\alpha \\in F$.\nProof: Assume for the sake of the contradiction that $\\alpha \\notin F$. Then since $F^\\cc$ is an open set (because $F$ is closed) there exists an $\\e \u0026gt; 0$ such that $(\\alpha - \\e, \\alpha + \\e) \\subset F^\\cc$. But this implies $\\alpha - \\frac{\\e}{2}$ is an upper bound for $F$ which is lower that $\\alpha$. This gives us our required contradiction. $\\square$\nProperties We now have all the tools to prove a very useful characterization of upper and lower limits and the highlight of this post.\nTheorem 1: Let $\\sn$ be a sequence of real numbers. Let $E$ and $s^*$ have the same meaning as in Definition 5. Then $s^*$ has the following two properties:\n $s^* \\in E$. If $x \u0026gt; s^*$, there is an integer $N$ such that $n \\geq N$ implies $s_n \u0026lt; x$.  Moreover, $s^*$ is the only number with these two properties.\nOf course, an analogous result is true for $s_*$.\nProof: We start by showing the two properties.\n  We divide it into three cases depending on what value $s^*$ takes:\nIf $s^* = +\\infty$, then $E$ is not bounded above; hence $\\sn$ is not bounded above, and thus there is a subsequence $\\{s_{n_k}\\}$ such that $s_{n_k} \\to +\\infty$. Therefore, $+\\infty \\in E$ and thus $s^* \\in E$.\nIf $s^*$ is real, then $E$ is bounded above, and at least one subsequential limit exists by the definition of $\\sup$. Therefore, $s^* \\in E$ follows from the Lemmas 1 and 2, and the fact that $s^* = \\sup E$.\nIf $s^* = -\\infty$, then $E$ contains only one element, namely $-\\infty$, and there is no subsequential limit. Thus, $s^* \\in E$.\n  Suppose for the sake of contradiction that there is a number $x \u0026gt; s^*$ such that $s_n \\geq x$ for infinitely many values of $n$. Let\u0026rsquo;s denote this set of $n$'s with $\\mathcal{K}$ and let $\\{s_k\\}$$_{k \\in \\mathcal{K}}$ be this subsequence. If $\\{s_k\\}_{k \\in \\mathcal{K}}$ is unbounded then $s^* = +\\infty$ contradicting the fact that there exists an $x \u0026gt; s^*$. And if $\\{s_k\\}_{k \\in \\mathcal{K}}$ is bounded that it contains a convergent subsequence (Bolzano–Weierstrass theorem). Suppose this convergent subsequence converges to $y$. Then $y \\geq x \u0026gt; s^*$. This contradicts the definition of $s^*$.\n  To show the uniqueness, suppose there are two distinct numbers, $p$ and $q$, which satisfy the two properties, and suppose $p \u0026lt; q$. Choose $x$ such that $p \u0026lt; x \u0026lt; q$. Since $p$ satisfies the second property, we have $s_n \u0026lt; x$ for $n \\geq N$. But then $q$ cannot satisfy the second property. $\\square$\nAn intuitive theorem:\nTheorem 2: If $s_n \\leq t_n$ for $n \\geq N$, where $N \\in \\N$ is fixed, then $$\\limi s_n \\leq \\limi t_n,$$ $$\\lims s_n \\leq \\lims t_n$$\nProof: Let $s^* = \\lims s_n$ and $t^* = \\lims t_n$. Suppose for the sake of contradiction $t^* \u0026lt; s^*$. Choose $x$ such that $t^* \u0026lt; x \u0026lt; s^*$. Then by the second property of Theorem 1 there is an integer $N_1$ such that $n \\geq N_1$ implies $t_n \u0026lt; x$. Also by the first property there exists a subsequence $\\snk$ such that $s_{n_k} \\to s^*$. This implies that there exists an integer $N_2$ such that $n \\geq N_2$ implies $x \u0026lt; s_n$. But then for $n \\geq \\max\\{N_1, N_2\\}$ we have $t_n \u0026lt; x \u0026lt; s_n$. This gives us our required contradiction.\nA similar argument can be made for the $\\liminf$ case. $\\square$\nNext we give a necessary and sufficient condition for the convergence of a sequence in terms of its $\\liminf$ and $\\limsup$.\nTheorem 3: For a real-valued sequence $\\sn$, $\\limm s_n = s \\in \\RR$ if and only if $$\\lims s_n = \\limi s_n = s$$\nProof: We divide the analysis into three cases.\nFirst, let $s \\in \\R$. Then if $\\lims s_n = \\limi s_n = s$, Theorem 1 implies that for any $\\e \u0026gt; 0$ we have $s_n \\in (s-\\e, s+\\e)$ for all but finitely many $n$, which means $s_n \\to s$. On the other hand if $s_n \\to s$ then every subsequence $\\snk$ must converge to $s$ and hence $\\lims s_n = \\limi s_n = s$.\nNow let $s = +\\infty$. Then $s_n \\to s$, i.e., for every $M \\in \\R$ there is an integer $N$ such that $n \\geq N$ implies $s_n \\geq M$ if and only $\\limi s_n = +\\infty$, and then $\\lims s_n = +\\infty$ since $\\limi s_n \\leq \\lims s_n$.\nLastly, let $s = -\\infty$. Then $s_n \\to s$, i.e., for every $M \\in \\R$ there is an integer $N$ such that $n \\geq N$ implies $s_n \\leq M$ if and only $\\lims s_n = -\\infty$, and then $\\limi s_n = -\\infty$ since $\\limi s_n \\leq \\lims s_n$. $\\square$\nUpper and lower limits - a reprise There is an equivalent way to express upper and lower limits.\nDefinition 6: Let $\\sn$ be a sequence of real numbers. We define the notation $$\\sups := \\sup \\{ s_k : k \\geq n\\}$$ $$\\infs := \\inf \\{ s_k : k \\geq n\\}$$\nWe note that the sequence $\\{ \\sups \\}$$_{n \\in \\N}$ is monotonically decreasing and the sequence $\\{ \\infs \\}$$_{n \\in \\N}$ is monotonically increasing, and thus their limits exist in $\\RR$.\nWe now show the equivalence of the two ways of looking at upper and lower limits.\nTheorem 4: Let $\\sn$ be a sequence of real numbers. Then $$\\limm \\sups = \\lims s_n$$ $$\\limm \\infs = \\limi s_n$$\nProof: We will prove the first equation. The proof for the second is similar. We prove the equation in two steps.\nLet $S = \\{ s_n : n \\in \\N \\}$. Let\u0026rsquo;s show that $\\sup S = +\\infty$ if and only if $\\lims s_n = + \\infty$. Suppose first that $\\sup S = + \\infty$. Then we construct a subsequence $\\snk$ as follows. We let $n_1 = 1.$ Suppose $n_1, \\ldots, n_{k}$ are chosen and let $$S_k = \\{ n \\in \\N : s_n \\geq \\max\\{s_{n_1}, \\ldots, s_{n_k}, k\\} + 1 \\}$$ Notice that $S_k$ is infinite as otherwise we can find an $M \\in \\R$ such that $s_n \\leq M$ for all $n \\geq 1$, contradicting the fact that $\\sup S = + \\infty$. We pick $n_{k+1}$ to be the smallest element of $S_k$ which is bigger than $n_k$. The resulting subsequence satisfies the condition that $s_{n_k} \\geq k$ for $k \\geq 2$ and thus we conclude that $s_{n_k} \\to +\\infty$ which gives $\\lims s_n = +\\infty$. Now suppose that $\\lims s_n = +\\infty$. From Theorem 1 we can conclude that there exists a subsequence $\\snk$ such that $s_{n_k} \\to +\\infty$. This immediately implies $\\sup S = +\\infty$.\nFor the second step, suppose $\\sup S \u0026lt; + \\infty$. Let $$a_n = \\sups$$ Notice that $a_1 \u0026lt; +\\infty$ and $\\{a_n\\}$ is a monotonically decreasing sequence. Therefore, we have that either $\\{a_n\\}$ is lower bounded in which case it converges to, say, $a$ or it is not in which case $\\limm a_n = -\\infty$. Since $s_n \\leq a_n$, by Theorem 2 we can conclude $$ \\lims s_n \\leq \\lims a_n = \\limm a_n $$ where the last equality follows from Theorem 3. We will now show that $$ \\lims s_n \\geq \\limm a_n $$ which will give us our required equality. If $\\limm a_n = -\\infty$ there is nothing to prove and so we assume that $a \u0026gt; -\\infty$. Let $\\e \u0026gt; 0$ be given and let $$ B = \\{ n \\in \\N : s_n \\geq a - \\e \\} $$ We claim that $B$ is infinite. Indeed, if $B$ were finite we can find $N \\in \\N$ so that $N \\geq \\max(B)$. This will imply that $s_n \\leq a - \\e$ for all $n \\geq N$ and so $a_n \\leq a - \\e$ for $n \\geq N$. But then by Theorem 2 we would conclude $a = \\limm a_n \\leq a-\\e$, which is absurd. Thus $B$ is infinite and we let $\\snk$ be a subsequence of $\\sn$ with $n_k \\in B$. Notice that $\\lims s_{n_k} \\leq \\lims s_n$, since any subsequential limit of $\\snk$ is also a subsequential limit of $\\sn$. This along with Theorem 2 give $$ a - \\e \\leq \\lims s_{n_k} \\leq \\lims s_n $$ Since $\\e$ was arbitrary we conclude that $\\lims s_n \\geq a$, which is what we wanted. $\\square$\nMore properties These theorems open new avenues to discover more properties of upper and lower limits.\nTheorem 5: Let $\\sn$ be a sequence of real numbers. Then $$\\limi s_n = - \\lims (-s_n)$$\nProof: TODO\nSubadditivity of $\\limsup$:\nTheorem 6: For any two real sequences $\\{a_n\\}$ and $\\{b_n\\}$, $$ \\lims (a_n + b_n) \\leq \\lims a_n + \\lims b_n $$ provided the sum on the right is not of the form $\\infty - \\infty$.\nProof: If $\\lims a_n = \\infty$ then as by assumption the right side is not $\\infty - \\infty$, it is $\\infty$ and there is nothing to prove. Similarly for the case $\\lims b_n = \\infty$. We may thus assume that $$ \\lims a_n = A \u0026lt; \\infty \\text{ and } \\lims b_n = B \u0026lt; \\infty $$ We note that $\\sup_{k \\geq 1} a_k \u0026lt; \\infty$, $\\sup_{k \\geq 1} b_k \u0026lt; \\infty$, and so TODO\nSuperadditivity of $\\liminf$:\nTheorem 7: For any two real sequences $\\{a_n\\}$ and $\\{b_n\\}$, $$ \\limi (a_n + b_n) \\geq \\limi a_n + \\limi b_n $$ provided the sum on the right is not of the form $\\infty - \\infty$.\nProof: TODO\n","date":1592426033,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592426033,"objectID":"4fb8d43db098b4713ceef892d1d72774","permalink":"https://makkar.github.io/post/upper-and-lower-limits/","publishdate":"2020-06-17T16:33:53-04:00","relpermalink":"/post/upper-and-lower-limits/","section":"post","summary":"A reference for a useful concept.","tags":[],"title":"Upper and Lower Limits","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c7634463bc503571b81622dfbdaae48f","permalink":"https://makkar.github.io/hilbert/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/hilbert/","section":"","summary":"Blog","tags":null,"title":"Hilbert's Hotel","type":"widget_page"},{"authors":null,"categories":null,"content":"Title: Bayesian nonparametric ensemble Date: June 17, 2020 Tags: bayesian Summary: This work improves upon the BNE model of Liu et al. (2019) using the methods proposed by Rahimi and Recht (2007).\nIntroduction $$ \\mathbb{E}[X] = \\int_{\\Omega} X ;\\text{dP} $$\nProblem Setting BNE ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"79a589979f0bc90d50d8da1239fec4e1","permalink":"https://makkar.github.io/research/bayesian-ensemble/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/bayesian-ensemble/","section":"research","summary":"Title: Bayesian nonparametric ensemble Date: June 17, 2020 Tags: bayesian Summary: This work improves upon the BNE model of Liu et al. (2019) using the methods proposed by Rahimi and Recht (2007).","tags":null,"title":"","type":"research"}]